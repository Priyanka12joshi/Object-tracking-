{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f449a8b-0f4b-4a7e-bd17-29f78744d514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC pressed, exiting...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keyboard\n",
    "import numpy as np\n",
    "\n",
    "def object_detection(video_path=None, object_detector=cv2.createBackgroundSubtractorMOG2(), contour_area_threshold=100):\n",
    "    # Choose the video source\n",
    "    if video_path:\n",
    "        cap = cv2.VideoCapture(video_path)  # Use video file\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(0)  # Use live video (camera)\n",
    "    \n",
    "    while True:\n",
    "        # Capture each frame\n",
    "        ret, frame = cap.read()\n",
    "        parallelogram_left_points = np.array([[0, 0], [0, 90],  [80,45],[90, 0],], dtype=np.int32)\n",
    "        parallelogram_center_points = np.array([[80,45],[90, 0], [200, 0],[150,45]], dtype=np.int32)\n",
    "        parallelogram_right_points = np.array([[200, 0],[150,45],[255,100], [255, 0]], dtype=np.int32)\n",
    "\n",
    "        frame = cv2.resize(frame,(224,224))\n",
    "        # If frame reading failed, exit loop\n",
    "        if not ret:\n",
    "            print(\"Video finished or camera feed not available.\")\n",
    "            break\n",
    "        cv2.fillPoly(frame, [parallelogram_left_points], (255, 255, 255))\n",
    "        cv2.fillPoly(frame, [parallelogram_center_points], (255, 255, 255))\n",
    "        cv2.fillPoly(frame, [parallelogram_right_points], (255, 255, 255))\n",
    "        # Apply background subtraction to get the masks for MOG2 and KNN\n",
    "        mask = object_detector.apply(frame)\n",
    "        \n",
    "        # Find contours of the detected objects for both MOG2 and KNN\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw bounding boxes for objects with a contour area larger than the threshold\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > contour_area_threshold:\n",
    "                (x, y, w, h) = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw bounding box for MOG2\n",
    "\n",
    "        mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Stack the original frame and the mask horizontally\n",
    "        stacked_frame = cv2.hconcat([frame, mask_bgr])\n",
    "        \n",
    "        # Display the stacked frames\n",
    "        cv2.imshow('Feed', stacked_frame)\n",
    "\n",
    "        # Check if 'ESC' key is pressed using the keyboard module\n",
    "        cv2.waitKey(1)\n",
    "        if keyboard.is_pressed('esc'):\n",
    "            print(\"ESC pressed, exiting...\")\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "object_detection(\n",
    "    video_path='./test.mp4',           # Pass video path or None for live video\n",
    "    contour_area_threshold=500  # Minimum contour area to filter small objects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb33827-ff4f-4518-9fda-0d2a82d63d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 1527 km/h\n",
      "Speed: 69 km/h\n",
      "Speed: 190 km/h\n",
      "Speed: 0 km/h\n",
      "Speed: 12 km/h\n",
      "Speed: 968 km/h\n",
      "Speed: 971 km/h\n",
      "Speed: 0 km/h\n",
      "Speed: 43 km/h\n",
      "Speed: 79 km/h\n",
      "Speed: 88 km/h\n",
      "Speed: 101 km/h\n",
      "Speed: 48 km/h\n",
      "Speed: 48 km/h\n",
      "Speed: 62 km/h\n",
      "Speed: 57 km/h\n",
      "Speed: 65 km/h\n",
      "Speed: 12 km/h\n",
      "Speed: 90 km/h\n",
      "Speed: 77 km/h\n",
      "Speed: 52 km/h\n",
      "Speed: 27 km/h\n",
      "Speed: 54 km/h\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keyboard\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return math.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
    "\n",
    "# Function to calculate speed in km/h\n",
    "def calculate_speed_in_kmh(point1, point2, scale_factor, fps):\n",
    "    # Calculate pixel distance between two points\n",
    "    pixel_distance = np.linalg.norm(np.array(point2) - np.array(point1))\n",
    "    \n",
    "    # Convert pixel distance to meters using scale factor (pixels to meters)\n",
    "    distance_in_meters = pixel_distance * scale_factor\n",
    "    \n",
    "    # Time per frame (seconds)\n",
    "    time_per_frame = 1 / fps\n",
    "    \n",
    "    # Calculate speed in meters per second (m/s)\n",
    "    speed_mps = distance_in_meters / time_per_frame\n",
    "    \n",
    "    # Convert speed to km/h (1 m/s = 3.6 km/h)\n",
    "    speed_kmh = speed_mps * 3.6\n",
    "    \n",
    "    return speed_kmh\n",
    "\n",
    "def object_detection(video_path=None, object_detector=cv2.createBackgroundSubtractorMOG2(), \n",
    "                     contour_area_threshold=100, scale_factor=0.05):\n",
    "    # Choose the video source\n",
    "    if video_path:\n",
    "        cap = cv2.VideoCapture(video_path)  # Use video file\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(0)  # Use live video (camera)\n",
    "\n",
    "    # Get frame rate of the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "\n",
    "    # Initialize variables to store previous vehicle positions\n",
    "    previous_positions = {}\n",
    "\n",
    "    while True:\n",
    "        # Capture each frame\n",
    "        ret, frame = cap.read()\n",
    "        parallelogram_left_points = np.array([[0, 0], [0, 90], [80, 45], [90, 0]], dtype=np.int32)\n",
    "        parallelogram_center_points = np.array([[80, 45], [90, 0], [200, 0], [150, 45]], dtype=np.int32)\n",
    "        parallelogram_right_points = np.array([[200, 0], [150, 45], [255, 100], [255, 0]], dtype=np.int32)\n",
    "\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        # If frame reading failed, exit loop\n",
    "        if not ret:\n",
    "            print(\"Video finished or camera feed not available.\")\n",
    "            break\n",
    "\n",
    "        # Fill parallelogram regions (optional - can be removed if not required)\n",
    "        cv2.fillPoly(frame, [parallelogram_left_points], (255, 255, 255))\n",
    "        cv2.fillPoly(frame, [parallelogram_center_points], (255, 255, 255))\n",
    "        cv2.fillPoly(frame, [parallelogram_right_points], (255, 255, 255))\n",
    "\n",
    "        # Apply background subtraction to get the masks for MOG2\n",
    "        mask = object_detector.apply(frame)\n",
    "\n",
    "        # Find contours of the detected objects\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        # To store current frame's positions of detected vehicles\n",
    "        current_positions = {}\n",
    "\n",
    "        # Draw bounding boxes for objects with a contour area larger than the threshold\n",
    "        for idx, contour in enumerate(contours):\n",
    "            if cv2.contourArea(contour) > contour_area_threshold:\n",
    "                (x, y, w, h) = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw bounding box for detected objects\n",
    "\n",
    "                # Calculate the center point of the bounding box (assumed as the vehicle position)\n",
    "                center_point = (x + w // 2, y + h // 2)\n",
    "\n",
    "                # Save current position for the vehicle (indexed by contour id)\n",
    "                current_positions[idx] = center_point\n",
    "\n",
    "                # Calculate speed if the vehicle was detected in the previous frame\n",
    "                if idx in previous_positions:\n",
    "                    # Get previous position\n",
    "                    prev_center_point = previous_positions[idx]\n",
    "\n",
    "                    # Calculate speed in km/h using scale factor (pixels to meters) and fps\n",
    "                    speed_kmh = calculate_speed_in_kmh(prev_center_point, center_point, scale_factor, fps)\n",
    "\n",
    "                    # Display the speed on the frame\n",
    "                    cv2.putText(frame, f\"Speed: {int(speed_kmh)} km/h\", (x, y - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    print(f\"Speed: {int(speed_kmh)} km/h\")\n",
    "\n",
    "        # Update the previous positions for the next frame\n",
    "        previous_positions = current_positions.copy()\n",
    "\n",
    "        mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Stack the original frame and the mask horizontally\n",
    "        stacked_frame = cv2.hconcat([frame, mask_bgr])\n",
    "\n",
    "        # Display the stacked frames\n",
    "        cv2.imshow('Vehicle Detection and Speed', stacked_frame)\n",
    "\n",
    "        # Check if 'ESC' key is pressed using the keyboard module\n",
    "        cv2.waitKey(1)\n",
    "        if keyboard.is_pressed('esc'):\n",
    "            print(\"ESC pressed, exiting...\")\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "object_detection(\n",
    "    video_path='./test.mp4',           # Pass video path or None for live video\n",
    "    contour_area_threshold=1000,        # Minimum contour area to filter small objects\n",
    "    scale_factor=0.08                  # Scale factor (meters per pixel)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97207d-1888-4674-9a2a-964a0fbbe7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
